{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import subprocess\n",
    "\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     ## 폰트 관련\n",
    "#     subprocess.run([\"sudo\", \"apt-get\", \"install\", \"-y\", \"fonts-nanum\"])\n",
    "#     subprocess.run([\"sudo\", \"fc-cache\", \"-fv\"])\n",
    "#     subprocess.run([\"rm\", \"-rf\", \"~/.cache/matplotlib\"]) \n",
    "#     # KoBERT와 sentencepiece 설치\n",
    "#     subprocess.run([\"pip\", \"install\", \"git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf\"])\n",
    "#     subprocess.run([\"pip\", \"install\", \"sentencepiece\"])\n",
    "#     subprocess.run([\"pip\", \"install\", \"datasets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/Othercomputers/내 MacBook Air/Documents/personal_llm_projects/dacon_merong/'\n",
    "else:\n",
    "    path = '../'\n",
    "\n",
    "data_path =  path + 'data/' + '{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 문제 해결\n",
    "# matplotlib은 한글 폰트를 지원하지 않음\n",
    "# os정보\n",
    "import platform\n",
    "\n",
    "# font_manager : 폰트 관리 모듈\n",
    "# rc : 폰트 변경 모듈\n",
    "from matplotlib import font_manager, rc\n",
    "# unicode 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # 폰트 경로 찾기\n",
    "    plt.rc('font', family='NanumBarunGothic')\n",
    "    plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "elif platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic') # os가 macos\n",
    "elif platform.system() == 'Windows':\n",
    "    path = 'c:/Windows/Fonts/malgun.ttf' # os가 windows\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print(\"Unknown System\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactive Optimizer for DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 2614.1794\n",
      "Epoch [1000/5000], Loss: 1266.7375\n",
      "Epoch [1500/5000], Loss: 633.9652\n",
      "Epoch [2000/5000], Loss: 402.0826\n",
      "Epoch [2500/5000], Loss: 232.8163\n",
      "Epoch [3000/5000], Loss: 114.7139\n",
      "Epoch [3500/5000], Loss: 44.6261\n",
      "Epoch [4000/5000], Loss: 7.0094\n",
      "Epoch [4500/5000], Loss: 1.4004\n",
      "Epoch [5000/5000], Loss: 0.3564\n",
      "학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 깊이 5의 MLP 모델 정의 (Dropout 포함)\n",
    "class DeepANN(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=128, output_size=1, dropout_prob=0.0):\n",
    "        super(DeepANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        # self.fc4 = nn.Linear(hidden_size // 4, hidden_size // 8)\n",
    "        self.fc5 = nn.Linear(hidden_size // 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        # x = self.dropout(F.relu(self.fc3(x)))  # Dropout은 여기까지만 적용\n",
    "        # x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)  # 마지막 레이어에는 활성화 함수 X\n",
    "        return x\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = 10\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "learning_rate = 0.001  # 학습률 감소\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 초기화\n",
    "model = DeepANN(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 더미 데이터 생성\n",
    "x_train = torch.ones(100, input_size) * (torch.rand([100,input_size]) * 20)\n",
    "x_mean = x_train.mean(dim=1)\n",
    "# y_train = ((x_train.mean(dim=1) * 3 + 5) + torch.randn([x_train.shape[0]]) *0.1  ).unsqueeze(1)  # 차원 맞추기\n",
    "y_train = ((3* x_mean * x_mean + 5 * x_mean +1)+ torch.randn([x_train.shape[0]]) *0.1  ).unsqueeze(1)  # 차원 맞추기\n",
    "\n",
    "# 학습 과정\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 500 == 0:  # 500번마다 출력\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"학습 완료!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 2.098465919494629\n",
      "실제값: 43.0\n"
     ]
    }
   ],
   "source": [
    "# 예측 (평가 모드)\n",
    "model.eval()\n",
    "test_input  = torch.ones([1, input_size]) * 3\n",
    "test_mean = test_input.mean(dim=1)\n",
    "with torch.no_grad():\n",
    "    pred = model(test_input)\n",
    "\n",
    "print('예측값:', pred.item())\n",
    "print('실제값:', (3 * test_mean * test_mean + 5 * test_mean +1).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.tensor([1,2]).unsqueeze(0)\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow =  next(iter(model.fc1.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0267,  0.1749,  0.3378,  ...,  0.3572, -0.0099,  0.3429],\n",
       "        [-0.0911, -0.1270, -0.0851,  ..., -0.2633,  0.4055,  0.1302],\n",
       "        [ 0.3075,  0.3172,  0.1539,  ..., -0.1694, -0.2756, -0.1516],\n",
       "        ...,\n",
       "        [ 0.3017, -0.2872,  0.1753,  ...,  0.1161, -0.5035, -0.1019],\n",
       "        [ 0.0150,  0.1756,  0.0742,  ...,  0.1252,  0.2372,  0.0529],\n",
       "        [-0.1688,  0.1289, -0.2143,  ..., -0.0678,  0.0393,  0.3430]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secondllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
